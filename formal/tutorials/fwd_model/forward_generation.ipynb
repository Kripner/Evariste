{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent.parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a forward model and generate some statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m[MIGRATION] - Changing decoding to decoding_params prefixes in flatdict\u001b[0m\n",
      "INFO - 03/01/21 11:33:06 - 2 days, 18:58:21 - Created dictionary with 4410 words (4356 total).\n",
      "INFO - 03/01/21 11:33:06 - 2 days, 18:58:21 - Model trained for 22 epoches\n",
      "INFO - 03/01/21 11:33:06 - 2 days, 18:58:21 - Fp16: False\n"
     ]
    }
   ],
   "source": [
    "from evariste.generation.cli.factories import forward_prover_from_checkpoint\n",
    "from evariste.generation.forward_prover import ProverConfig, AsyncProver\n",
    "from evariste.generation.cli.fwd_configs import DECODING\n",
    "\n",
    "checkpoint_path = \"\"\n",
    "\n",
    "prover, dico, params, env_helper = forward_prover_from_checkpoint(\n",
    "    ckpt_path=checkpoint_path,\n",
    "    device=\"cuda\",\n",
    "    # No idea what's in there, but I assume it samples rather than use a beam search\n",
    "    cfg=DECODING[\"sampling\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evariste.generation.fwd_eq.eq_env_helper import eq_env_goal_stream\n",
    "from numpy.random.mtrand import RandomState\n",
    "\n",
    "metadata = {}\n",
    "rng = RandomState()\n",
    "\n",
    "# Define a fixed length iterator over goals.\n",
    "def gs(env_helper, rng, metadata, n_goals):\n",
    "    for i in range(n_goals):\n",
    "        goal = env_helper.build_generation_goal(rng=rng)\n",
    "        metadata[i] = {}\n",
    "        yield i, goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal stream defines `tasks` for the prover. We can now launch a `proof_iterator` and inspect the result.\n",
    "\n",
    "`proof.info` tells us why the generation stopped. Here, we see that the generation stopped when a `stop_tactic` was generated. Since this is what I wanted to introduce in this [PR](https://github.com/fairinternal/Evariste/pull/376), I'm happy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationInfos(n_invalid_consecutive=0, stopped=('stop_tactic', 9), solved=False)\n",
      "GenerationInfos(n_invalid_consecutive=0, stopped=('stop_tactic', 9), solved=False)\n",
      "GenerationInfos(n_invalid_consecutive=0, stopped=('stop_tactic', 10), solved=False)\n",
      "GenerationInfos(n_invalid_consecutive=0, stopped=('stop_tactic', 10), solved=False)\n",
      "GenerationInfos(n_invalid_consecutive=0, stopped=('stop_tactic', 12), solved=False)\n",
      "GenerationInfos(n_invalid_consecutive=0, stopped=('stop_tactic', 14), solved=False)\n",
      "GenerationInfos(n_invalid_consecutive=0, stopped=('stop_tactic', 15), solved=False)\n",
      "GenerationInfos(n_invalid_consecutive=0, stopped=('stop_tactic', 16), solved=False)\n",
      "GenerationInfos(n_invalid_consecutive=0, stopped=('stop_tactic', 16), solved=False)\n",
      "GenerationInfos(n_invalid_consecutive=0, stopped=('stop_tactic', 17), solved=False)\n"
     ]
    }
   ],
   "source": [
    "goal_stream = gs(env_helper, rng, metadata, 10)\n",
    "proof_iterator = prover.prove(goal_stream)\n",
    "all_proofs = [proof for _, proof in proof_iterator]\n",
    "for proof in all_proofs:\n",
    "    print(proof.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we want to look at a specific generation. As expected, the last statement corresponding to the `stop_action` is None. Everything went well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add max x0 max + 6 mul tan add + 5 0 x1 + 1 2 cosh x0 <EQ_DELIMITOR> add max x0 max + 6 atanh tanh mul tan add + 5 0 x1 + 1 2 cosh x0\n",
      "add max x0 max + 6 mul tan add + 5 0 x1 + 1 2 cosh x0 <EQ_DELIMITOR> add max x0 max + 6 atanh tanh mul + 1 2 tan add + 5 0 x1 cosh x0\n",
      "add max x0 max + 6 mul tan add + 5 0 x1 + 1 2 cosh x0 <EQ_DELIMITOR> add max x0 max + 6 atanh tanh mul + 1 2 tan add + 5 0 x1 mul add exp x0 exp neg x0 inv + 2\n",
      "add max x0 max + 6 mul tan add + 5 0 x1 + 1 2 cosh x0 <EQ_DELIMITOR> asinh sinh add max x0 max + 6 atanh tanh mul + 1 2 tan add + 5 0 x1 mul add exp x0 exp neg x0 inv + 2\n",
      "add max x0 max + 6 mul tan add + 5 0 x1 + 1 2 cosh x0 <EQ_DELIMITOR> asinh sinh add max x0 max + 6 atanh tanh mul + 1 2 tan asin sin add + 5 0 x1 mul add exp x0 exp neg x0 inv + 2\n",
      "add max x0 max + 6 mul tan add + 5 0 x1 + 1 2 cosh x0 <EQ_DELIMITOR> pow2 sqrt asinh sinh add max x0 max + 6 atanh tanh mul + 1 2 tan asin sin add + 5 0 x1 mul add exp x0 exp neg x0 inv + 2\n",
      "add max x0 max + 6 mul tan add + 5 0 x1 + 1 2 cosh x0 <EQ_DELIMITOR> pow2 sqrt asinh sinh add mul add exp x0 exp neg x0 inv + 2 max x0 max + 6 atanh tanh mul + 1 2 tan asin sin add + 5 0 x1\n",
      "add max x0 max + 6 mul tan add + 5 0 x1 + 1 2 cosh x0 <EQ_DELIMITOR> pow2 sqrt asinh sinh add mul add exp x0 exp neg x0 inv + 2 max x0 max + 6 atanh tanh mul + 1 2 mul sin asin sin add + 5 0 x1 inv cos asin sin add + 5 0 x1\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "one_proof = all_proofs[0]\n",
    "for step in one_proof.generation.forward_steps():\n",
    "    print(step.statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
